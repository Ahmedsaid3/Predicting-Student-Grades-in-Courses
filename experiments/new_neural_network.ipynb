{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6751e7-635f-490a-a5e1-800729e763cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.special import softmax as scipy_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1194fc38-c3fa-4a0e-a65b-14942de11f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./processed_data_course_based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d6934c-be6b-4b55-b14d-44e1324b26f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Number</th>\n",
       "      <th>Course Title</th>\n",
       "      <th>Course Credit</th>\n",
       "      <th>Grades</th>\n",
       "      <th>Course Semester</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Completed Credits</th>\n",
       "      <th>Semester GPA</th>\n",
       "      <th>Semester Credit</th>\n",
       "      <th>Grade 1 Rate</th>\n",
       "      <th>Grade 2 Rate</th>\n",
       "      <th>Grade 3 Rate</th>\n",
       "      <th>Grade 4 Rate</th>\n",
       "      <th>Grade 5 Rate</th>\n",
       "      <th>Mean Grade</th>\n",
       "      <th>STDEV Grade</th>\n",
       "      <th>Mean GPA</th>\n",
       "      <th>STDEV GPA</th>\n",
       "      <th>Department Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ideological and Moral Cultivation and Legal Fo...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>0.408377</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>3.547120</td>\n",
       "      <td>0.677055</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Success: Career Planning</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.557592</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>0.298429</td>\n",
       "      <td>3.552356</td>\n",
       "      <td>1.025211</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Introduction to Computer Science</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.107330</td>\n",
       "      <td>0.358639</td>\n",
       "      <td>0.429319</td>\n",
       "      <td>0.096859</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.841040</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Advanced Mathematics A(1)</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.193717</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>0.240838</td>\n",
       "      <td>0.217277</td>\n",
       "      <td>3.193717</td>\n",
       "      <td>1.359003</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>College English A(1)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.256545</td>\n",
       "      <td>0.439791</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>2.981675</td>\n",
       "      <td>0.843178</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>381</td>\n",
       "      <td>J2EE Framework</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.790076</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.348168</td>\n",
       "      <td>0.400524</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>3.510471</td>\n",
       "      <td>0.886555</td>\n",
       "      <td>3.220775</td>\n",
       "      <td>0.515869</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>381</td>\n",
       "      <td>Intellectual Property and Software Protection</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>0.227749</td>\n",
       "      <td>0.366492</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>3.722513</td>\n",
       "      <td>1.007305</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>381</td>\n",
       "      <td>Human-Computer Interaction Technology</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060209</td>\n",
       "      <td>0.413613</td>\n",
       "      <td>0.408377</td>\n",
       "      <td>0.117801</td>\n",
       "      <td>3.583770</td>\n",
       "      <td>0.774968</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>381</td>\n",
       "      <td>Software Development and Testing Training</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.476440</td>\n",
       "      <td>0.463351</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>3.528796</td>\n",
       "      <td>0.608736</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>381</td>\n",
       "      <td>Python Language Programming</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>0.282723</td>\n",
       "      <td>0.235602</td>\n",
       "      <td>3.586387</td>\n",
       "      <td>1.025462</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Student Number                                       Course Title  \\\n",
       "0                   0  Ideological and Moral Cultivation and Legal Fo...   \n",
       "1                   0                           Success: Career Planning   \n",
       "2                   0                   Introduction to Computer Science   \n",
       "3                   0                          Advanced Mathematics A(1)   \n",
       "4                   0                               College English A(1)   \n",
       "...               ...                                                ...   \n",
       "19095             381                                     J2EE Framework   \n",
       "19096             381      Intellectual Property and Software Protection   \n",
       "19097             381              Human-Computer Interaction Technology   \n",
       "19098             381          Software Development and Testing Training   \n",
       "19099             381                        Python Language Programming   \n",
       "\n",
       "       Course Credit  Grades  Course Semester       GPA  Completed Credits  \\\n",
       "0                2.5       4                1  3.102564               19.5   \n",
       "1                1.0       3                1  3.102564               19.5   \n",
       "2                2.0       1                1  3.102564               19.5   \n",
       "3                5.5       4                1  3.102564               19.5   \n",
       "4                4.0       3                1  3.102564               19.5   \n",
       "...              ...     ...              ...       ...                ...   \n",
       "19095            4.5       3                6  2.790076              131.0   \n",
       "19096            1.0       4                7  2.838129              139.0   \n",
       "19097            2.0       5                7  2.838129              139.0   \n",
       "19098            3.0       3                7  2.838129              139.0   \n",
       "19099            2.0       3                7  2.838129              139.0   \n",
       "\n",
       "       Semester GPA  Semester Credit  Grade 1 Rate  Grade 2 Rate  \\\n",
       "0          3.102564             19.5      0.000000      0.023560   \n",
       "1          3.102564             19.5      0.005236      0.086387   \n",
       "2          3.102564             19.5      0.007853      0.107330   \n",
       "3          3.102564             19.5      0.143979      0.193717   \n",
       "4          3.102564             19.5      0.028796      0.256545   \n",
       "...             ...              ...           ...           ...   \n",
       "19095      2.800000             20.0      0.007853      0.120419   \n",
       "19096      3.625000              8.0      0.000000      0.151832   \n",
       "19097      3.625000              8.0      0.000000      0.060209   \n",
       "19098      3.625000              8.0      0.000000      0.018325   \n",
       "19099      3.625000              8.0      0.000000      0.167539   \n",
       "\n",
       "       Grade 3 Rate  Grade 4 Rate  Grade 5 Rate  Mean Grade  STDEV Grade  \\\n",
       "0          0.486911      0.408377      0.081152    3.547120     0.677055   \n",
       "1          0.557592      0.052356      0.298429    3.552356     1.025211   \n",
       "2          0.358639      0.429319      0.096859    3.500000     0.841040   \n",
       "3          0.204188      0.240838      0.217277    3.193717     1.359003   \n",
       "4          0.439791      0.253927      0.020942    2.981675     0.843178   \n",
       "...             ...           ...           ...         ...          ...   \n",
       "19095      0.348168      0.400524      0.123037    3.510471     0.886555   \n",
       "19096      0.227749      0.366492      0.253927    3.722513     1.007305   \n",
       "19097      0.413613      0.408377      0.117801    3.583770     0.774968   \n",
       "19098      0.476440      0.463351      0.041885    3.528796     0.608736   \n",
       "19099      0.314136      0.282723      0.235602    3.586387     1.025462   \n",
       "\n",
       "       Mean GPA  STDEV GPA Department Code  \n",
       "0      3.307021   0.516455             BLG  \n",
       "1      3.307021   0.516455             BLG  \n",
       "2      3.307021   0.516455             BLG  \n",
       "3      3.307021   0.516455             BLG  \n",
       "4      3.307021   0.516455             BLG  \n",
       "...         ...        ...             ...  \n",
       "19095  3.220775   0.515869             BLG  \n",
       "19096  3.241516   0.494006             BLG  \n",
       "19097  3.241516   0.494006             BLG  \n",
       "19098  3.241516   0.494006             BLG  \n",
       "19099  3.241516   0.494006             BLG  \n",
       "\n",
       "[19100 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78198760-e40d-4695-88cb-130270cd2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([df.columns[0], df.columns[1]] ,inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f5003c-542c-4528-8793-08aaf8e74482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Credit</th>\n",
       "      <th>Grades</th>\n",
       "      <th>Course Semester</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Completed Credits</th>\n",
       "      <th>Semester GPA</th>\n",
       "      <th>Semester Credit</th>\n",
       "      <th>Grade 1 Rate</th>\n",
       "      <th>Grade 2 Rate</th>\n",
       "      <th>Grade 3 Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Grade 5 Rate</th>\n",
       "      <th>Mean Grade</th>\n",
       "      <th>STDEV Grade</th>\n",
       "      <th>Mean GPA</th>\n",
       "      <th>STDEV GPA</th>\n",
       "      <th>Department Code</th>\n",
       "      <th>Course Level</th>\n",
       "      <th>Status</th>\n",
       "      <th>Standing</th>\n",
       "      <th>Course Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>3.547120</td>\n",
       "      <td>0.677055</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.557592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298429</td>\n",
       "      <td>3.552356</td>\n",
       "      <td>1.025211</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.107330</td>\n",
       "      <td>0.358639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096859</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.841040</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Unsuccessful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.193717</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217277</td>\n",
       "      <td>3.193717</td>\n",
       "      <td>1.359003</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.256545</td>\n",
       "      <td>0.439791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>2.981675</td>\n",
       "      <td>0.843178</td>\n",
       "      <td>3.307021</td>\n",
       "      <td>0.516455</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Freshman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.790076</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.348168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123037</td>\n",
       "      <td>3.510471</td>\n",
       "      <td>0.886555</td>\n",
       "      <td>3.220775</td>\n",
       "      <td>0.515869</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Junior</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>0.227749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253927</td>\n",
       "      <td>3.722513</td>\n",
       "      <td>1.007305</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Senior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060209</td>\n",
       "      <td>0.413613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117801</td>\n",
       "      <td>3.583770</td>\n",
       "      <td>0.774968</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Senior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.476440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>3.528796</td>\n",
       "      <td>0.608736</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Senior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235602</td>\n",
       "      <td>3.586387</td>\n",
       "      <td>1.025462</td>\n",
       "      <td>3.241516</td>\n",
       "      <td>0.494006</td>\n",
       "      <td>BLG</td>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>Successful</td>\n",
       "      <td>Senior</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Course Credit  Grades  Course Semester       GPA  Completed Credits  \\\n",
       "0                2.5       4                1  3.102564               19.5   \n",
       "1                1.0       3                1  3.102564               19.5   \n",
       "2                2.0       1                1  3.102564               19.5   \n",
       "3                5.5       4                1  3.102564               19.5   \n",
       "4                4.0       3                1  3.102564               19.5   \n",
       "...              ...     ...              ...       ...                ...   \n",
       "19095            4.5       3                6  2.790076              131.0   \n",
       "19096            1.0       4                7  2.838129              139.0   \n",
       "19097            2.0       5                7  2.838129              139.0   \n",
       "19098            3.0       3                7  2.838129              139.0   \n",
       "19099            2.0       3                7  2.838129              139.0   \n",
       "\n",
       "       Semester GPA  Semester Credit  Grade 1 Rate  Grade 2 Rate  \\\n",
       "0          3.102564             19.5      0.000000      0.023560   \n",
       "1          3.102564             19.5      0.005236      0.086387   \n",
       "2          3.102564             19.5      0.007853      0.107330   \n",
       "3          3.102564             19.5      0.143979      0.193717   \n",
       "4          3.102564             19.5      0.028796      0.256545   \n",
       "...             ...              ...           ...           ...   \n",
       "19095      2.800000             20.0      0.007853      0.120419   \n",
       "19096      3.625000              8.0      0.000000      0.151832   \n",
       "19097      3.625000              8.0      0.000000      0.060209   \n",
       "19098      3.625000              8.0      0.000000      0.018325   \n",
       "19099      3.625000              8.0      0.000000      0.167539   \n",
       "\n",
       "       Grade 3 Rate  ...  Grade 5 Rate  Mean Grade  STDEV Grade  Mean GPA  \\\n",
       "0          0.486911  ...      0.081152    3.547120     0.677055  3.307021   \n",
       "1          0.557592  ...      0.298429    3.552356     1.025211  3.307021   \n",
       "2          0.358639  ...      0.096859    3.500000     0.841040  3.307021   \n",
       "3          0.204188  ...      0.217277    3.193717     1.359003  3.307021   \n",
       "4          0.439791  ...      0.020942    2.981675     0.843178  3.307021   \n",
       "...             ...  ...           ...         ...          ...       ...   \n",
       "19095      0.348168  ...      0.123037    3.510471     0.886555  3.220775   \n",
       "19096      0.227749  ...      0.253927    3.722513     1.007305  3.241516   \n",
       "19097      0.413613  ...      0.117801    3.583770     0.774968  3.241516   \n",
       "19098      0.476440  ...      0.041885    3.528796     0.608736  3.241516   \n",
       "19099      0.314136  ...      0.235602    3.586387     1.025462  3.241516   \n",
       "\n",
       "       STDEV GPA  Department Code   Course Level        Status  Standing  \\\n",
       "0       0.516455              BLG  Undergraduate    Successful  Freshman   \n",
       "1       0.516455              BLG  Undergraduate    Successful  Freshman   \n",
       "2       0.516455              BLG  Undergraduate  Unsuccessful  Freshman   \n",
       "3       0.516455              BLG  Undergraduate    Successful  Freshman   \n",
       "4       0.516455              BLG  Undergraduate    Successful  Freshman   \n",
       "...          ...              ...            ...           ...       ...   \n",
       "19095   0.515869              BLG  Undergraduate    Successful    Junior   \n",
       "19096   0.494006              BLG  Undergraduate    Successful    Senior   \n",
       "19097   0.494006              BLG  Undergraduate    Successful    Senior   \n",
       "19098   0.494006              BLG  Undergraduate    Successful    Senior   \n",
       "19099   0.494006              BLG  Undergraduate    Successful    Senior   \n",
       "\n",
       "      Course Year  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  \n",
       "...           ...  \n",
       "19095           3  \n",
       "19096           4  \n",
       "19097           4  \n",
       "19098           4  \n",
       "19099           4  \n",
       "\n",
       "[19100 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Course Level\"] = \"Undergraduate\"\n",
    "df['Status'] = np.where(df['Grades'] != 1, 'Successful', 'Unsuccessful')\n",
    "conditions = [\n",
    "    (df['Course Semester'] <= 2),\n",
    "    (df['Course Semester'] >= 3) & (df['Course Semester'] <= 4),\n",
    "    (df['Course Semester'] >= 5) & (df['Course Semester'] <= 6),\n",
    "    (df['Course Semester'] == 7)\n",
    "]\n",
    "\n",
    "choices = ['Freshman', 'Sophomore', 'Junior', 'Senior']\n",
    "\n",
    "# Create the new 'standing' column\n",
    "df['Standing'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "# Create Course Year column\n",
    "choices = [1, 2, 3, 4]\n",
    "\n",
    "df[\"Course Year\"] = np.select(conditions, choices, default=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced96182-47d8-4cd8-b8cd-4c11505741d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Course Year'], prefix='Course Year'), pd.get_dummies(df['Department Code'], prefix='Department Code'), pd.get_dummies(df['Course Level'], prefix='Course Level'), pd.get_dummies(df['Standing'], prefix='Standing'), pd.get_dummies(df['Status'], prefix='Status')], axis=1)\n",
    "df.drop(['Course Year', 'Department Code', 'Course Level', 'Status', 'Standing'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcc66edb-3103-4533-9a7a-1c0de6861892",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17bbbba8-a7fc-4a63-96e5-bf70496af87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LabelEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.LabelEncoder.html\">?<span>Documentation for LabelEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LabelEncoder()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(['1', '2', '3', '4', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f194701e-0998-4d95-9cda-df488b3db8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train, X_test):\n",
    "    X_train_cols = X_train.columns\n",
    "    X_test_cols = X_test.columns\n",
    "    sc = StandardScaler()\n",
    "    fitted_sc = sc.fit(X_train)\n",
    "    X_train_std = pd.DataFrame(fitted_sc.transform(X_train), columns=X_train_cols)\n",
    "    X_test_std = pd.DataFrame(fitted_sc.transform(X_test), columns=X_test_cols)\n",
    "    return X_train_std, X_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a3447a-266f-4812-8986-25ff0b76dc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Credit</th>\n",
       "      <th>Grades</th>\n",
       "      <th>Course Semester</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Completed Credits</th>\n",
       "      <th>Semester GPA</th>\n",
       "      <th>Semester Credit</th>\n",
       "      <th>Grade 1 Rate</th>\n",
       "      <th>Grade 2 Rate</th>\n",
       "      <th>Grade 3 Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Course Year_3</th>\n",
       "      <th>Course Year_4</th>\n",
       "      <th>Department Code_BLG</th>\n",
       "      <th>Course Level_Undergraduate</th>\n",
       "      <th>Standing_Freshman</th>\n",
       "      <th>Standing_Junior</th>\n",
       "      <th>Standing_Senior</th>\n",
       "      <th>Standing_Sophomore</th>\n",
       "      <th>Status_Successful</th>\n",
       "      <th>Status_Unsuccessful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.486911</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>0.557592</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.107330</td>\n",
       "      <td>0.358639</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.143979</td>\n",
       "      <td>0.193717</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.102564</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.256545</td>\n",
       "      <td>0.439791</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.790076</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.120419</td>\n",
       "      <td>0.348168</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>0.227749</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060209</td>\n",
       "      <td>0.413613</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.476440</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.838129</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167539</td>\n",
       "      <td>0.314136</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19100 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Course Credit  Grades  Course Semester       GPA  Completed Credits  \\\n",
       "0                2.5       4                1  3.102564               19.5   \n",
       "1                1.0       3                1  3.102564               19.5   \n",
       "2                2.0       1                1  3.102564               19.5   \n",
       "3                5.5       4                1  3.102564               19.5   \n",
       "4                4.0       3                1  3.102564               19.5   \n",
       "...              ...     ...              ...       ...                ...   \n",
       "19095            4.5       3                6  2.790076              131.0   \n",
       "19096            1.0       4                7  2.838129              139.0   \n",
       "19097            2.0       5                7  2.838129              139.0   \n",
       "19098            3.0       3                7  2.838129              139.0   \n",
       "19099            2.0       3                7  2.838129              139.0   \n",
       "\n",
       "       Semester GPA  Semester Credit  Grade 1 Rate  Grade 2 Rate  \\\n",
       "0          3.102564             19.5      0.000000      0.023560   \n",
       "1          3.102564             19.5      0.005236      0.086387   \n",
       "2          3.102564             19.5      0.007853      0.107330   \n",
       "3          3.102564             19.5      0.143979      0.193717   \n",
       "4          3.102564             19.5      0.028796      0.256545   \n",
       "...             ...              ...           ...           ...   \n",
       "19095      2.800000             20.0      0.007853      0.120419   \n",
       "19096      3.625000              8.0      0.000000      0.151832   \n",
       "19097      3.625000              8.0      0.000000      0.060209   \n",
       "19098      3.625000              8.0      0.000000      0.018325   \n",
       "19099      3.625000              8.0      0.000000      0.167539   \n",
       "\n",
       "       Grade 3 Rate  ...  Course Year_3  Course Year_4  Department Code_BLG  \\\n",
       "0          0.486911  ...          False          False                 True   \n",
       "1          0.557592  ...          False          False                 True   \n",
       "2          0.358639  ...          False          False                 True   \n",
       "3          0.204188  ...          False          False                 True   \n",
       "4          0.439791  ...          False          False                 True   \n",
       "...             ...  ...            ...            ...                  ...   \n",
       "19095      0.348168  ...           True          False                 True   \n",
       "19096      0.227749  ...          False           True                 True   \n",
       "19097      0.413613  ...          False           True                 True   \n",
       "19098      0.476440  ...          False           True                 True   \n",
       "19099      0.314136  ...          False           True                 True   \n",
       "\n",
       "       Course Level_Undergraduate  Standing_Freshman  Standing_Junior  \\\n",
       "0                            True               True            False   \n",
       "1                            True               True            False   \n",
       "2                            True               True            False   \n",
       "3                            True               True            False   \n",
       "4                            True               True            False   \n",
       "...                           ...                ...              ...   \n",
       "19095                        True              False             True   \n",
       "19096                        True              False            False   \n",
       "19097                        True              False            False   \n",
       "19098                        True              False            False   \n",
       "19099                        True              False            False   \n",
       "\n",
       "       Standing_Senior  Standing_Sophomore  Status_Successful  \\\n",
       "0                False               False               True   \n",
       "1                False               False               True   \n",
       "2                False               False              False   \n",
       "3                False               False               True   \n",
       "4                False               False               True   \n",
       "...                ...                 ...                ...   \n",
       "19095            False               False               True   \n",
       "19096             True               False               True   \n",
       "19097             True               False               True   \n",
       "19098             True               False               True   \n",
       "19099             True               False               True   \n",
       "\n",
       "       Status_Unsuccessful  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                     True  \n",
       "3                    False  \n",
       "4                    False  \n",
       "...                    ...  \n",
       "19095                False  \n",
       "19096                False  \n",
       "19097                False  \n",
       "19098                False  \n",
       "19099                False  \n",
       "\n",
       "[19100 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68801176-e094-45b1-a6f0-0fd7521c76db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(df, train_sem, columns):\n",
    "    dataFrame = pd.DataFrame(columns=columns)\n",
    "    for sem in train_sem:\n",
    "        dataFrame = pd.concat([dataFrame, df[df.iloc[:, 2] == sem]], ignore_index=True)\n",
    "    \n",
    "    X_train = dataFrame.drop('Course Semester', axis=1)\n",
    "    y_train = le.transform(X_train.pop('Grades'))\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "208b643d-236e-4987-9f9d-a136a71a0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_structure(X, Y):\n",
    "    input_unit = X.shape[0] # size of input layer\n",
    "    hidden_unit = X.shape[0] # hidden layer of size 4\n",
    "    output_unit = Y.shape[0] # size of output layer\n",
    "    return (input_unit, hidden_unit, output_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccf7512b-8c79-4394-901b-f6f2c4283a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_initialization(input_unit, hidden_unit, output_unit):\n",
    "    np.random.seed(41)\n",
    "    W1 = np.random.randn(hidden_unit, input_unit) * 0.01\n",
    "    b1 = np.zeros((hidden_unit, 1))\n",
    "    W2 = np.random.randn(output_unit, hidden_unit) * 0.01\n",
    "    b2 = np.zeros((output_unit, 1))\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85fc76a4-3cba-461c-83e7-dd38a70d4e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return scipy_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dadad9d4-2b48-4db9-8f28-e145838545e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    cache = {\"Z1\": Z1,\"A1\": A1,\"Z2\": Z2,\"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6c71c9a-dbfb-4e12-9edf-641667650b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_cost(A2, Y, parameters):\n",
    "    #number of training example\n",
    "    m = Y.shape[1]\n",
    "    logprobs = np.multiply(np.log(A2), Y)\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    cost = float(np.squeeze(cost))\n",
    "                                    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c0ef13d-9ad5-40a5-a67a-43a1e263cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    #number of training example\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "   \n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T) \n",
    "    db1 = (1/m)*np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2,\"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56cc7417-f5bc-4c8c-9b17-2425189a05f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(parameters, grads, learning_rate = 0.01):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "   \n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    \n",
    "    parameters = {\"W1\": W1, \"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b312db42-b191-4144-b723-7e8d8e56c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(X, Y, hidden_unit, num_iterations = 98):\n",
    "    np.random.seed(3)\n",
    "    input_unit = define_structure(X, Y)[0]\n",
    "    output_unit = define_structure(X, Y)[2]\n",
    "    \n",
    "    parameters = parameters_initialization(input_unit, hidden_unit, output_unit)\n",
    "   \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        cost = entropy_cost(A2, Y, parameters)\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "        parameters = gradient_descent(parameters, grads)\n",
    "        if i % 5 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17597e76-96c4-481e-b348-49226206d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(parameters, X):\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.round(A2)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d42fd09-05c7-4838-873a-4d47f256d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_score(df, columns):\n",
    "    error_scores = {}\n",
    "    sorted_semesters = sorted(set(df.iloc[:, 2]))\n",
    "    for sem_idx in range(1, len(sorted_semesters)):\n",
    "        training_sem = sorted_semesters[:sem_idx]\n",
    "        test_sem = sorted_semesters[sem_idx]\n",
    "        X_train, y_train = get_train_data(df, training_sem, columns)\n",
    "        X_test = df[df.iloc[:, 2] == test_sem]\n",
    "        X_test.drop('Course Semester', axis=1, inplace=True)\n",
    "        y_test = le.transform(X_test.pop('Grades'))\n",
    "        \n",
    "        X_train, X_test = standardize(X_train, X_test)\n",
    "        \n",
    "        X_train = X_train.T.to_numpy()   # (number of attributes, number of samples)\n",
    "        y_train = y_train.reshape(1, y_train.shape[0])   # (1, number of samples)\n",
    "        \n",
    "        X_test = X_test.T.to_numpy()   # (number of attributes, number of samples)\n",
    "        y_test = y_test.reshape(1, y_test.shape[0])   # (1, number of samples)\n",
    "        \n",
    "        parameters = neural_network_model(X_train, y_train, 58, num_iterations=490)\n",
    "        \n",
    "        y_pred_test = prediction(parameters, X_test)\n",
    "        rmse_test = round(np.sqrt(mean_squared_error(y_test[0], y_pred_test[0])), 3)\n",
    "        mae_test = round(mean_absolute_error(y_test[0], y_pred_test[0]), 3)\n",
    "        \n",
    "        y_pred_train = prediction(parameters, X_train)\n",
    "        rmse_train = round(np.sqrt(mean_squared_error(y_train[0], y_pred_train[0])), 3)\n",
    "        mae_train = round(mean_absolute_error(y_train[0], y_pred_train[0]),3)\n",
    "        \n",
    "        error_scores.setdefault(sem_idx, {})\n",
    "        error_scores[sem_idx]['rmse'] = [rmse_train, rmse_test]\n",
    "        error_scores[sem_idx]['mae'] = [mae_train, mae_test]        \n",
    "        \n",
    "    return error_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3071f7fb-2119-441e-b0e3-1194ccd11655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb14eeb2-b37d-4e37-8156-e189e9773854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\982985509.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrame = pd.concat([dataFrame, df[df.iloc[:, 2] == sem]], ignore_index=True)\n",
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 18.911436\n",
      "Cost after iteration 5: 18.911047\n",
      "Cost after iteration 10: 18.910634\n",
      "Cost after iteration 15: 18.910182\n",
      "Cost after iteration 20: 18.909672\n",
      "Cost after iteration 25: 18.909084\n",
      "Cost after iteration 30: 18.908395\n",
      "Cost after iteration 35: 18.907577\n",
      "Cost after iteration 40: 18.906597\n",
      "Cost after iteration 45: 18.905415\n",
      "Cost after iteration 50: 18.903984\n",
      "Cost after iteration 55: 18.902248\n",
      "Cost after iteration 60: 18.900141\n",
      "Cost after iteration 65: 18.897588\n",
      "Cost after iteration 70: 18.894509\n",
      "Cost after iteration 75: 18.890817\n",
      "Cost after iteration 80: 18.886438\n",
      "Cost after iteration 85: 18.881316\n",
      "Cost after iteration 90: 18.875451\n",
      "Cost after iteration 95: 18.868936\n",
      "Cost after iteration 100: 18.862028\n",
      "Cost after iteration 105: 18.855240\n",
      "Cost after iteration 110: 18.849470\n",
      "Cost after iteration 115: 18.846173\n",
      "Cost after iteration 120: 18.847557\n",
      "Cost after iteration 125: 18.856825\n",
      "Cost after iteration 130: 18.878407\n",
      "Cost after iteration 135: 18.918182\n",
      "Cost after iteration 140: 18.983597\n",
      "Cost after iteration 145: 19.083561\n",
      "Cost after iteration 150: 19.227970\n",
      "Cost after iteration 155: 19.426706\n",
      "Cost after iteration 160: 19.688183\n",
      "Cost after iteration 165: 20.017707\n",
      "Cost after iteration 170: 20.416112\n",
      "Cost after iteration 175: 20.879020\n",
      "Cost after iteration 180: 21.396856\n",
      "Cost after iteration 185: 21.955496\n",
      "Cost after iteration 190: 22.537325\n",
      "Cost after iteration 195: 23.122514\n",
      "Cost after iteration 200: 23.690425\n",
      "Cost after iteration 205: 24.221053\n",
      "Cost after iteration 210: 24.696421\n",
      "Cost after iteration 215: 25.101766\n",
      "Cost after iteration 220: 25.426368\n",
      "Cost after iteration 225: 25.663902\n",
      "Cost after iteration 230: 25.812334\n",
      "Cost after iteration 235: 25.873478\n",
      "Cost after iteration 240: 25.852385\n",
      "Cost after iteration 245: 25.756704\n",
      "Cost after iteration 250: 25.596091\n",
      "Cost after iteration 255: 25.381634\n",
      "Cost after iteration 260: 25.125242\n",
      "Cost after iteration 265: 24.838975\n",
      "Cost after iteration 270: 24.534330\n",
      "Cost after iteration 275: 24.221590\n",
      "Cost after iteration 280: 23.909305\n",
      "Cost after iteration 285: 23.604010\n",
      "Cost after iteration 290: 23.310184\n",
      "Cost after iteration 295: 23.030437\n",
      "Cost after iteration 300: 22.765860\n",
      "Cost after iteration 305: 22.516448\n",
      "Cost after iteration 310: 22.281540\n",
      "Cost after iteration 315: 22.060188\n",
      "Cost after iteration 320: 21.851441\n",
      "Cost after iteration 325: 21.654511\n",
      "Cost after iteration 330: 21.468837\n",
      "Cost after iteration 335: 21.294072\n",
      "Cost after iteration 340: 21.130012\n",
      "Cost after iteration 345: 20.976509\n",
      "Cost after iteration 350: 20.833396\n",
      "Cost after iteration 355: 20.700427\n",
      "Cost after iteration 360: 20.577256\n",
      "Cost after iteration 365: 20.463440\n",
      "Cost after iteration 370: 20.358452\n",
      "Cost after iteration 375: 20.261713\n",
      "Cost after iteration 380: 20.172619\n",
      "Cost after iteration 385: 20.090562\n",
      "Cost after iteration 390: 20.014951\n",
      "Cost after iteration 395: 19.945227\n",
      "Cost after iteration 400: 19.880864\n",
      "Cost after iteration 405: 19.821379\n",
      "Cost after iteration 410: 19.766330\n",
      "Cost after iteration 415: 19.715315\n",
      "Cost after iteration 420: 19.667972\n",
      "Cost after iteration 425: 19.623974\n",
      "Cost after iteration 430: 19.583025\n",
      "Cost after iteration 435: 19.544862\n",
      "Cost after iteration 440: 19.509245\n",
      "Cost after iteration 445: 19.475960\n",
      "Cost after iteration 450: 19.444813\n",
      "Cost after iteration 455: 19.415632\n",
      "Cost after iteration 460: 19.388257\n",
      "Cost after iteration 465: 19.362549\n",
      "Cost after iteration 470: 19.338376\n",
      "Cost after iteration 475: 19.315624\n",
      "Cost after iteration 480: 19.294185\n",
      "Cost after iteration 485: 19.273964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\3765939947.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  logprobs = np.multiply(np.log(A2), Y)\n",
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\3765939947.py:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  logprobs = np.multiply(np.log(A2), Y)\n",
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\982985509.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrame = pd.concat([dataFrame, df[df.iloc[:, 2] == sem]], ignore_index=True)\n",
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 19.788679\n",
      "Cost after iteration 5: 19.788071\n",
      "Cost after iteration 10: 19.787433\n",
      "Cost after iteration 15: 19.786736\n",
      "Cost after iteration 20: 19.785950\n",
      "Cost after iteration 25: 19.785043\n",
      "Cost after iteration 30: 19.783975\n",
      "Cost after iteration 35: 19.782699\n",
      "Cost after iteration 40: 19.781160\n",
      "Cost after iteration 45: 19.779293\n",
      "Cost after iteration 50: 19.777019\n",
      "Cost after iteration 55: 19.774248\n",
      "Cost after iteration 60: 19.770874\n",
      "Cost after iteration 65: 19.766782\n",
      "Cost after iteration 70: 19.761852\n",
      "Cost after iteration 75: 19.755974\n",
      "Cost after iteration 80: 19.749066\n",
      "Cost after iteration 85: 19.741119\n",
      "Cost after iteration 90: 19.732258\n",
      "Cost after iteration 95: 19.722839\n",
      "Cost after iteration 100: 19.713586\n",
      "Cost after iteration 105: 19.705784\n",
      "Cost after iteration 110: 19.701532\n",
      "Cost after iteration 115: 19.704032\n",
      "Cost after iteration 120: 19.717921\n",
      "Cost after iteration 125: 19.749557\n",
      "Cost after iteration 130: 19.807207\n",
      "Cost after iteration 135: 19.901000\n",
      "Cost after iteration 140: 20.042497\n",
      "Cost after iteration 145: 20.243767\n",
      "Cost after iteration 150: 20.515953\n",
      "Cost after iteration 155: 20.867540\n",
      "Cost after iteration 160: 21.302728\n",
      "Cost after iteration 165: 21.820337\n",
      "Cost after iteration 170: 22.413465\n",
      "Cost after iteration 175: 23.069890\n",
      "Cost after iteration 180: 23.773003\n",
      "Cost after iteration 185: 24.503070\n",
      "Cost after iteration 190: 25.238630\n",
      "Cost after iteration 195: 25.957891\n",
      "Cost after iteration 200: 26.640032\n",
      "Cost after iteration 205: 27.266330\n",
      "Cost after iteration 210: 27.821054\n",
      "Cost after iteration 215: 28.292103\n",
      "Cost after iteration 220: 28.671335\n",
      "Cost after iteration 225: 28.954619\n",
      "Cost after iteration 230: 29.141611\n",
      "Cost after iteration 235: 29.235336\n",
      "Cost after iteration 240: 29.241654\n",
      "Cost after iteration 245: 29.168634\n",
      "Cost after iteration 250: 29.025904\n",
      "Cost after iteration 255: 28.823964\n",
      "Cost after iteration 260: 28.573525\n",
      "Cost after iteration 265: 28.284941\n",
      "Cost after iteration 270: 27.967768\n",
      "Cost after iteration 275: 27.630508\n",
      "Cost after iteration 280: 27.280511\n",
      "Cost after iteration 285: 26.923990\n",
      "Cost after iteration 290: 26.566123\n",
      "Cost after iteration 295: 26.211184\n",
      "Cost after iteration 300: 25.862686\n",
      "Cost after iteration 305: 25.523483\n",
      "Cost after iteration 310: 25.195837\n",
      "Cost after iteration 315: 24.881440\n",
      "Cost after iteration 320: 24.581433\n",
      "Cost after iteration 325: 24.296440\n",
      "Cost after iteration 330: 24.026647\n",
      "Cost after iteration 335: 23.771924\n",
      "Cost after iteration 340: 23.531961\n",
      "Cost after iteration 345: 23.306397\n",
      "Cost after iteration 350: 23.094894\n",
      "Cost after iteration 355: 22.897162\n",
      "Cost after iteration 360: 22.712941\n",
      "Cost after iteration 365: 22.541958\n",
      "Cost after iteration 370: 22.383883\n",
      "Cost after iteration 375: 22.238294\n",
      "Cost after iteration 380: 22.104656\n",
      "Cost after iteration 385: 21.982306\n",
      "Cost after iteration 390: 21.870450\n",
      "Cost after iteration 395: 21.768158\n",
      "Cost after iteration 400: 21.674379\n",
      "Cost after iteration 405: 21.587960\n",
      "Cost after iteration 410: 21.507693\n",
      "Cost after iteration 415: 21.432370\n",
      "Cost after iteration 420: 21.360869\n",
      "Cost after iteration 425: 21.292230\n",
      "Cost after iteration 430: 21.225730\n",
      "Cost after iteration 435: 21.160918\n",
      "Cost after iteration 440: 21.097610\n",
      "Cost after iteration 445: 21.035837\n",
      "Cost after iteration 450: 20.975772\n",
      "Cost after iteration 455: 20.917647\n",
      "Cost after iteration 460: 20.861692\n",
      "Cost after iteration 465: 20.808090\n",
      "Cost after iteration 470: 20.756961\n",
      "Cost after iteration 475: 20.708359\n",
      "Cost after iteration 480: 20.662280\n",
      "Cost after iteration 485: 20.618675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\982985509.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrame = pd.concat([dataFrame, df[df.iloc[:, 2] == sem]], ignore_index=True)\n",
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 19.560010\n",
      "Cost after iteration 5: 19.559120\n",
      "Cost after iteration 10: 19.558178\n",
      "Cost after iteration 15: 19.557144\n",
      "Cost after iteration 20: 19.555972\n",
      "Cost after iteration 25: 19.554611\n",
      "Cost after iteration 30: 19.553002\n",
      "Cost after iteration 35: 19.551076\n",
      "Cost after iteration 40: 19.548752\n",
      "Cost after iteration 45: 19.545936\n",
      "Cost after iteration 50: 19.542521\n",
      "Cost after iteration 55: 19.538386\n",
      "Cost after iteration 60: 19.533407\n",
      "Cost after iteration 65: 19.527461\n",
      "Cost after iteration 70: 19.520456\n",
      "Cost after iteration 75: 19.512364\n",
      "Cost after iteration 80: 19.503286\n",
      "Cost after iteration 85: 19.493548\n",
      "Cost after iteration 90: 19.483848\n",
      "Cost after iteration 95: 19.475457\n",
      "Cost after iteration 100: 19.470490\n",
      "Cost after iteration 105: 19.472226\n",
      "Cost after iteration 110: 19.485451\n",
      "Cost after iteration 115: 19.516737\n",
      "Cost after iteration 120: 19.574537\n",
      "Cost after iteration 125: 19.668967\n",
      "Cost after iteration 130: 19.811152\n",
      "Cost after iteration 135: 20.012165\n",
      "Cost after iteration 140: 20.281733\n",
      "Cost after iteration 145: 20.626977\n",
      "Cost after iteration 150: 21.051488\n",
      "Cost after iteration 155: 21.554826\n",
      "Cost after iteration 160: 22.132417\n",
      "Cost after iteration 165: 22.775728\n",
      "Cost after iteration 170: 23.472636\n",
      "Cost after iteration 175: 24.207985\n",
      "Cost after iteration 180: 24.964337\n",
      "Cost after iteration 185: 25.722899\n",
      "Cost after iteration 190: 26.464502\n",
      "Cost after iteration 195: 27.170574\n",
      "Cost after iteration 200: 27.824007\n",
      "Cost after iteration 205: 28.409949\n",
      "Cost after iteration 210: 28.916514\n",
      "Cost after iteration 215: 29.335386\n",
      "Cost after iteration 220: 29.662183\n",
      "Cost after iteration 225: 29.896442\n",
      "Cost after iteration 230: 30.041156\n",
      "Cost after iteration 235: 30.101967\n",
      "Cost after iteration 240: 30.086249\n",
      "Cost after iteration 245: 30.002311\n",
      "Cost after iteration 250: 29.858815\n",
      "Cost after iteration 255: 29.664397\n",
      "Cost after iteration 260: 29.427409\n",
      "Cost after iteration 265: 29.155760\n",
      "Cost after iteration 270: 28.856821\n",
      "Cost after iteration 275: 28.537383\n",
      "Cost after iteration 280: 28.203611\n",
      "Cost after iteration 285: 27.860973\n",
      "Cost after iteration 290: 27.514174\n",
      "Cost after iteration 295: 27.167128\n",
      "Cost after iteration 300: 26.823019\n",
      "Cost after iteration 305: 26.484422\n",
      "Cost after iteration 310: 26.153464\n",
      "Cost after iteration 315: 25.831938\n",
      "Cost after iteration 320: 25.521365\n",
      "Cost after iteration 325: 25.222980\n",
      "Cost after iteration 330: 24.937704\n",
      "Cost after iteration 335: 24.666113\n",
      "Cost after iteration 340: 24.408453\n",
      "Cost after iteration 345: 24.164678\n",
      "Cost after iteration 350: 23.934515\n",
      "Cost after iteration 355: 23.717541\n",
      "Cost after iteration 360: 23.513248\n",
      "Cost after iteration 365: 23.321088\n",
      "Cost after iteration 370: 23.140483\n",
      "Cost after iteration 375: 22.970813\n",
      "Cost after iteration 380: 22.811391\n",
      "Cost after iteration 385: 22.661449\n",
      "Cost after iteration 390: 22.520139\n",
      "Cost after iteration 395: 22.386559\n",
      "Cost after iteration 400: 22.259795\n",
      "Cost after iteration 405: 22.138984\n",
      "Cost after iteration 410: 22.023368\n",
      "Cost after iteration 415: 21.912347\n",
      "Cost after iteration 420: 21.805493\n",
      "Cost after iteration 425: 21.702535\n",
      "Cost after iteration 430: 21.603323\n",
      "Cost after iteration 435: 21.507790\n",
      "Cost after iteration 440: 21.415921\n",
      "Cost after iteration 445: 21.327730\n",
      "Cost after iteration 450: 21.243243\n",
      "Cost after iteration 455: 21.162482\n",
      "Cost after iteration 460: 21.085449\n",
      "Cost after iteration 465: 21.012121\n",
      "Cost after iteration 470: 20.942442\n",
      "Cost after iteration 475: 20.876325\n",
      "Cost after iteration 480: 20.813653\n",
      "Cost after iteration 485: 20.754291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\982985509.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrame = pd.concat([dataFrame, df[df.iloc[:, 2] == sem]], ignore_index=True)\n",
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 20.520748\n",
      "Cost after iteration 5: 20.519934\n",
      "Cost after iteration 10: 20.519072\n",
      "Cost after iteration 15: 20.518123\n",
      "Cost after iteration 20: 20.517047\n",
      "Cost after iteration 25: 20.515796\n",
      "Cost after iteration 30: 20.514314\n",
      "Cost after iteration 35: 20.512537\n",
      "Cost after iteration 40: 20.510386\n",
      "Cost after iteration 45: 20.507769\n",
      "Cost after iteration 50: 20.504577\n",
      "Cost after iteration 55: 20.500682\n",
      "Cost after iteration 60: 20.495943\n",
      "Cost after iteration 65: 20.490204\n",
      "Cost after iteration 70: 20.483312\n",
      "Cost after iteration 75: 20.475134\n",
      "Cost after iteration 80: 20.465598\n",
      "Cost after iteration 85: 20.454760\n",
      "Cost after iteration 90: 20.442895\n",
      "Cost after iteration 95: 20.430655\n",
      "Cost after iteration 100: 20.419268\n",
      "Cost after iteration 105: 20.410814\n",
      "Cost after iteration 110: 20.408560\n",
      "Cost after iteration 115: 20.417319\n",
      "Cost after iteration 120: 20.443789\n",
      "Cost after iteration 125: 20.496756\n",
      "Cost after iteration 130: 20.587047\n",
      "Cost after iteration 135: 20.727080\n",
      "Cost after iteration 140: 20.929894\n",
      "Cost after iteration 145: 21.207665\n",
      "Cost after iteration 150: 21.569922\n",
      "Cost after iteration 155: 22.021860\n",
      "Cost after iteration 160: 22.563247\n",
      "Cost after iteration 165: 23.188145\n",
      "Cost after iteration 170: 23.885387\n",
      "Cost after iteration 175: 24.639558\n",
      "Cost after iteration 180: 25.432205\n",
      "Cost after iteration 185: 26.243087\n",
      "Cost after iteration 190: 27.051383\n",
      "Cost after iteration 195: 27.836780\n",
      "Cost after iteration 200: 28.580418\n",
      "Cost after iteration 205: 29.265662\n",
      "Cost after iteration 210: 29.878676\n",
      "Cost after iteration 215: 30.408793\n",
      "Cost after iteration 220: 30.848691\n",
      "Cost after iteration 225: 31.194387\n",
      "Cost after iteration 230: 31.445069\n",
      "Cost after iteration 235: 31.602782\n",
      "Cost after iteration 240: 31.672002\n",
      "Cost after iteration 245: 31.659102\n",
      "Cost after iteration 250: 31.571768\n",
      "Cost after iteration 255: 31.418418\n",
      "Cost after iteration 260: 31.207685\n",
      "Cost after iteration 265: 30.948020\n",
      "Cost after iteration 270: 30.647431\n",
      "Cost after iteration 275: 30.313365\n",
      "Cost after iteration 280: 29.952690\n",
      "Cost after iteration 285: 29.571744\n",
      "Cost after iteration 290: 29.176395\n",
      "Cost after iteration 295: 28.772086\n",
      "Cost after iteration 300: 28.363838\n",
      "Cost after iteration 305: 27.956231\n",
      "Cost after iteration 310: 27.553362\n",
      "Cost after iteration 315: 27.158808\n",
      "Cost after iteration 320: 26.775609\n",
      "Cost after iteration 325: 26.406257\n",
      "Cost after iteration 330: 26.052700\n",
      "Cost after iteration 335: 25.716356\n",
      "Cost after iteration 340: 25.398136\n",
      "Cost after iteration 345: 25.098483\n",
      "Cost after iteration 350: 24.817426\n",
      "Cost after iteration 355: 24.554649\n",
      "Cost after iteration 360: 24.309563\n",
      "Cost after iteration 365: 24.081378\n",
      "Cost after iteration 370: 23.869178\n",
      "Cost after iteration 375: 23.671968\n",
      "Cost after iteration 380: 23.488729\n",
      "Cost after iteration 385: 23.318448\n",
      "Cost after iteration 390: 23.160142\n",
      "Cost after iteration 395: 23.012877\n",
      "Cost after iteration 400: 22.875775\n",
      "Cost after iteration 405: 22.748016\n",
      "Cost after iteration 410: 22.628847\n",
      "Cost after iteration 415: 22.517571\n",
      "Cost after iteration 420: 22.413553\n",
      "Cost after iteration 425: 22.316212\n",
      "Cost after iteration 430: 22.225018\n",
      "Cost after iteration 435: 22.139487\n",
      "Cost after iteration 440: 22.059180\n",
      "Cost after iteration 445: 21.983696\n",
      "Cost after iteration 450: 21.912671\n",
      "Cost after iteration 455: 21.845771\n",
      "Cost after iteration 460: 21.782694\n",
      "Cost after iteration 465: 21.723162\n",
      "Cost after iteration 470: 21.666922\n",
      "Cost after iteration 475: 21.613744\n",
      "Cost after iteration 480: 21.563414\n",
      "Cost after iteration 485: 21.515739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\982985509.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrame = pd.concat([dataFrame, df[df.iloc[:, 2] == sem]], ignore_index=True)\n",
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 21.385400\n",
      "Cost after iteration 5: 21.384537\n",
      "Cost after iteration 10: 21.383620\n",
      "Cost after iteration 15: 21.382606\n",
      "Cost after iteration 20: 21.381450\n",
      "Cost after iteration 25: 21.380098\n",
      "Cost after iteration 30: 21.378487\n",
      "Cost after iteration 35: 21.376543\n",
      "Cost after iteration 40: 21.374178\n",
      "Cost after iteration 45: 21.371286\n",
      "Cost after iteration 50: 21.367743\n",
      "Cost after iteration 55: 21.363405\n",
      "Cost after iteration 60: 21.358114\n",
      "Cost after iteration 65: 21.351703\n",
      "Cost after iteration 70: 21.344015\n",
      "Cost after iteration 75: 21.334937\n",
      "Cost after iteration 80: 21.324459\n",
      "Cost after iteration 85: 21.312762\n",
      "Cost after iteration 90: 21.300371\n",
      "Cost after iteration 95: 21.288358\n",
      "Cost after iteration 100: 21.278635\n",
      "Cost after iteration 105: 21.274328\n",
      "Cost after iteration 110: 21.280205\n",
      "Cost after iteration 115: 21.303109\n",
      "Cost after iteration 120: 21.352282\n",
      "Cost after iteration 125: 21.439422\n",
      "Cost after iteration 130: 21.578288\n",
      "Cost after iteration 135: 21.783708\n",
      "Cost after iteration 140: 22.069963\n",
      "Cost after iteration 145: 22.448755\n",
      "Cost after iteration 150: 22.927174\n",
      "Cost after iteration 155: 23.506171\n",
      "Cost after iteration 160: 24.179885\n",
      "Cost after iteration 165: 24.935906\n",
      "Cost after iteration 170: 25.756323\n",
      "Cost after iteration 175: 26.619262\n",
      "Cost after iteration 180: 27.500634\n",
      "Cost after iteration 185: 28.375824\n",
      "Cost after iteration 190: 29.221172\n",
      "Cost after iteration 195: 30.015146\n",
      "Cost after iteration 200: 30.739178\n",
      "Cost after iteration 205: 31.378169\n",
      "Cost after iteration 210: 31.920699\n",
      "Cost after iteration 215: 32.359027\n",
      "Cost after iteration 220: 32.688951\n",
      "Cost after iteration 225: 32.909579\n",
      "Cost after iteration 230: 33.023031\n",
      "Cost after iteration 235: 33.034079\n",
      "Cost after iteration 240: 32.949760\n",
      "Cost after iteration 245: 32.778986\n",
      "Cost after iteration 250: 32.532189\n",
      "Cost after iteration 255: 32.220969\n",
      "Cost after iteration 260: 31.857717\n",
      "Cost after iteration 265: 31.455149\n",
      "Cost after iteration 270: 31.025752\n",
      "Cost after iteration 275: 30.581188\n",
      "Cost after iteration 280: 30.131741\n",
      "Cost after iteration 285: 29.685911\n",
      "Cost after iteration 290: 29.250209\n",
      "Cost after iteration 295: 28.829187\n",
      "Cost after iteration 300: 28.425665\n",
      "Cost after iteration 305: 28.041094\n",
      "Cost after iteration 310: 27.675964\n",
      "Cost after iteration 315: 27.330187\n",
      "Cost after iteration 320: 27.003380\n",
      "Cost after iteration 325: 26.695030\n",
      "Cost after iteration 330: 26.404546\n",
      "Cost after iteration 335: 26.131244\n",
      "Cost after iteration 340: 25.874299\n",
      "Cost after iteration 345: 25.632724\n",
      "Cost after iteration 350: 25.405388\n",
      "Cost after iteration 355: 25.191072\n",
      "Cost after iteration 360: 24.988566\n",
      "Cost after iteration 365: 24.796769\n",
      "Cost after iteration 370: 24.614764\n",
      "Cost after iteration 375: 24.441860\n",
      "Cost after iteration 380: 24.277577\n",
      "Cost after iteration 385: 24.121606\n",
      "Cost after iteration 390: 23.973740\n",
      "Cost after iteration 395: 23.833810\n",
      "Cost after iteration 400: 23.701647\n",
      "Cost after iteration 405: 23.577042\n",
      "Cost after iteration 410: 23.459744\n",
      "Cost after iteration 415: 23.349458\n",
      "Cost after iteration 420: 23.245850\n",
      "Cost after iteration 425: 23.148566\n",
      "Cost after iteration 430: 23.057234\n",
      "Cost after iteration 435: 22.971483\n",
      "Cost after iteration 440: 22.890946\n",
      "Cost after iteration 445: 22.815267\n",
      "Cost after iteration 450: 22.744110\n",
      "Cost after iteration 455: 22.677154\n",
      "Cost after iteration 460: 22.614101\n",
      "Cost after iteration 465: 22.554673\n",
      "Cost after iteration 470: 22.498611\n",
      "Cost after iteration 475: 22.445677\n",
      "Cost after iteration 480: 22.395652\n",
      "Cost after iteration 485: 22.348334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\982985509.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataFrame = pd.concat([dataFrame, df[df.iloc[:, 2] == sem]], ignore_index=True)\n",
      "C:\\Users\\casperrrr\\AppData\\Local\\Temp\\ipykernel_28972\\393110090.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('Course Semester', axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 22.158871\n",
      "Cost after iteration 5: 22.158076\n",
      "Cost after iteration 10: 22.157231\n",
      "Cost after iteration 15: 22.156298\n",
      "Cost after iteration 20: 22.155234\n",
      "Cost after iteration 25: 22.153991\n",
      "Cost after iteration 30: 22.152513\n",
      "Cost after iteration 35: 22.150732\n",
      "Cost after iteration 40: 22.148568\n",
      "Cost after iteration 45: 22.145926\n",
      "Cost after iteration 50: 22.142697\n",
      "Cost after iteration 55: 22.138752\n",
      "Cost after iteration 60: 22.133955\n",
      "Cost after iteration 65: 22.128162\n",
      "Cost after iteration 70: 22.121246\n",
      "Cost after iteration 75: 22.113130\n",
      "Cost after iteration 80: 22.103842\n",
      "Cost after iteration 85: 22.093608\n",
      "Cost after iteration 90: 22.082994\n",
      "Cost after iteration 95: 22.073111\n",
      "Cost after iteration 100: 22.065890\n",
      "Cost after iteration 105: 22.064440\n",
      "Cost after iteration 110: 22.073444\n",
      "Cost after iteration 115: 22.099548\n",
      "Cost after iteration 120: 22.151624\n",
      "Cost after iteration 125: 22.240756\n",
      "Cost after iteration 130: 22.379801\n",
      "Cost after iteration 135: 22.582420\n",
      "Cost after iteration 140: 22.861641\n",
      "Cost after iteration 145: 23.228164\n",
      "Cost after iteration 150: 23.688764\n",
      "Cost after iteration 155: 24.245093\n",
      "Cost after iteration 160: 24.893060\n",
      "Cost after iteration 165: 25.622799\n",
      "Cost after iteration 170: 26.419171\n",
      "Cost after iteration 175: 27.262714\n",
      "Cost after iteration 180: 28.130920\n",
      "Cost after iteration 185: 28.999665\n",
      "Cost after iteration 190: 29.844669\n",
      "Cost after iteration 195: 30.642840\n",
      "Cost after iteration 200: 31.373405\n",
      "Cost after iteration 205: 32.018776\n",
      "Cost after iteration 210: 32.565099\n",
      "Cost after iteration 215: 33.002568\n",
      "Cost after iteration 220: 33.325508\n",
      "Cost after iteration 225: 33.532275\n",
      "Cost after iteration 230: 33.624974\n",
      "Cost after iteration 235: 33.609011\n",
      "Cost after iteration 240: 33.492542\n",
      "Cost after iteration 245: 33.285927\n",
      "Cost after iteration 250: 33.001202\n",
      "Cost after iteration 255: 32.651590\n",
      "Cost after iteration 260: 32.250969\n",
      "Cost after iteration 265: 31.813265\n",
      "Cost after iteration 270: 31.351807\n",
      "Cost after iteration 275: 30.878730\n",
      "Cost after iteration 280: 30.404537\n",
      "Cost after iteration 285: 29.937869\n",
      "Cost after iteration 290: 29.485479\n",
      "Cost after iteration 295: 29.052350\n",
      "Cost after iteration 300: 28.641895\n",
      "Cost after iteration 305: 28.256173\n",
      "Cost after iteration 310: 27.896099\n",
      "Cost after iteration 315: 27.561633\n",
      "Cost after iteration 320: 27.251966\n",
      "Cost after iteration 325: 26.965703\n",
      "Cost after iteration 330: 26.701046\n",
      "Cost after iteration 335: 26.455973\n",
      "Cost after iteration 340: 26.228400\n",
      "Cost after iteration 345: 26.016300\n",
      "Cost after iteration 350: 25.817776\n",
      "Cost after iteration 355: 25.631105\n",
      "Cost after iteration 360: 25.454750\n",
      "Cost after iteration 365: 25.287391\n",
      "Cost after iteration 370: 25.127953\n",
      "Cost after iteration 375: 24.975631\n",
      "Cost after iteration 380: 24.829896\n",
      "Cost after iteration 385: 24.690459\n",
      "Cost after iteration 390: 24.557211\n",
      "Cost after iteration 395: 24.430145\n",
      "Cost after iteration 400: 24.309286\n",
      "Cost after iteration 405: 24.194638\n",
      "Cost after iteration 410: 24.086158\n",
      "Cost after iteration 415: 23.983740\n",
      "Cost after iteration 420: 23.887221\n",
      "Cost after iteration 425: 23.796384\n",
      "Cost after iteration 430: 23.710973\n",
      "Cost after iteration 435: 23.630707\n",
      "Cost after iteration 440: 23.555290\n",
      "Cost after iteration 445: 23.484422\n",
      "Cost after iteration 450: 23.417806\n",
      "Cost after iteration 455: 23.355156\n",
      "Cost after iteration 460: 23.296197\n",
      "Cost after iteration 465: 23.240670\n",
      "Cost after iteration 470: 23.188332\n",
      "Cost after iteration 475: 23.138959\n",
      "Cost after iteration 480: 23.092341\n",
      "Cost after iteration 485: 23.048284\n"
     ]
    }
   ],
   "source": [
    "scores = get_error_score(df, columns)\n",
    "model_results['NN'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c7a937a-9502-4332-a1f9-30ad7ba414d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_nn_results.json', 'w') as fw:\n",
    "    json.dump(model_results, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9aba7-21d0-4c6e-b587-c57ce0faa28a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
